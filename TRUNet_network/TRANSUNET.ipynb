{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboardX\n",
        "!pip install ml_collections\n",
        "!pip install monai"
      ],
      "metadata": {
        "id": "p60S4qp5GG3B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "0e0c20e8-e6ce-4af2-8057-5e26e9389cfc"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Requirement already satisfied: tensorboardX in /usr/local/lib/python3.10/dist-packages (2.6.2.2)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (24.2)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (4.25.5)\n",
            "Requirement already satisfied: ml_collections in /usr/local/lib/python3.10/dist-packages (1.0.0)\n",
            "Requirement already satisfied: absl-py in /usr/local/lib/python3.10/dist-packages (from ml_collections) (1.4.0)\n",
            "Requirement already satisfied: six in /usr/local/lib/python3.10/dist-packages (from ml_collections) (1.17.0)\n",
            "Requirement already satisfied: PyYAML in /usr/local/lib/python3.10/dist-packages (from ml_collections) (6.0.2)\n",
            "Requirement already satisfied: monai in /usr/local/lib/python3.10/dist-packages (1.4.0)\n",
            "Requirement already satisfied: numpy<2.0,>=1.24 in /usr/local/lib/python3.10/dist-packages (from monai) (1.26.4)\n",
            "Requirement already satisfied: torch>=1.9 in /usr/local/lib/python3.10/dist-packages (from monai) (2.5.1+cu121)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.16.1)\n",
            "Requirement already satisfied: typing-extensions>=4.8.0 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (4.12.2)\n",
            "Requirement already satisfied: networkx in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.4.2)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (3.1.4)\n",
            "Requirement already satisfied: fsspec in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (2024.10.0)\n",
            "Requirement already satisfied: sympy==1.13.1 in /usr/local/lib/python3.10/dist-packages (from torch>=1.9->monai) (1.13.1)\n",
            "Requirement already satisfied: mpmath<1.4,>=1.1.0 in /usr/local/lib/python3.10/dist-packages (from sympy==1.13.1->torch>=1.9->monai) (1.3.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->torch>=1.9->monai) (3.0.2)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!git clone --branch training https://github.com/lesnikowka/TRUNet.git\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dabum2IYKdZC",
        "outputId": "54f8c72c-31cb-45d0-bca0-4740dd9f9656"
      },
      "execution_count": 8,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "fatal: destination path 'TRUNet' already exists and is not an empty directory.\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import os\n",
        "print(os.getcwd())\n",
        "import sys\n",
        "import os\n",
        "sys.path.append('/content/TRUNet')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "TPkfZ_1iK6XW",
        "outputId": "25e5e43f-e517-460d-8017-90e4fecc61d5"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "/content\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from tensorboardX import SummaryWriter\n",
        "from torch.utils.data import DataLoader\n",
        "from statistics import fmean\n",
        "\n",
        "\n",
        "def dice_score(pred, gt):  # data in shape [batch, classes, h, w, d]\n",
        "    dice = []\n",
        "    for batchloop in range(gt.shape[0]):\n",
        "        dice_tmp = []\n",
        "        for roi in range(gt.shape[1]):\n",
        "            if roi > 0:  # skip background\n",
        "                pred_tmp = pred[int(batchloop), int(roi)]\n",
        "                gt_tmp = gt[int(batchloop), int(roi)]\n",
        "                a = np.sum(pred_tmp[gt_tmp == 1])\n",
        "                b = np.sum(pred_tmp)\n",
        "                c = np.sum(gt_tmp)\n",
        "                if a == 0:\n",
        "                    metric = 0\n",
        "                else:\n",
        "                    metric_ = a * 2.0 / (b + c)\n",
        "                    metric = metric_.item()\n",
        "                dice_tmp.append(metric)\n",
        "        dice.append(fmean(dice_tmp))\n",
        "    return fmean(dice)\n",
        "\n",
        "\n",
        "def one_hot_encoder(input_tensor, n_classes):\n",
        "    tensor_list = []\n",
        "    for i in range(n_classes):\n",
        "        temp_prob = input_tensor == i  # * torch.ones_like(input_tensor)\n",
        "        tensor_list.append(temp_prob)\n",
        "    output_tensor = torch.cat(tensor_list, dim=1)\n",
        "    return output_tensor.float()\n",
        "\n",
        "\n",
        "def to_one_arr_encoding(input_tensor):  # input shape: [batch, channels, h, w, d]\n",
        "    new_arr = torch.zeros(input_tensor.shape)\n",
        "    for batchloop in range(input_tensor.shape[0]):\n",
        "        for d in range(input_tensor.shape[1]):\n",
        "            new_arr[batchloop, d] = torch.where(input_tensor[batchloop, d] == 1, d + 1, 0)\n",
        "    return new_arr.sum(1).unsqueeze(1)\n",
        "\n",
        "\n",
        "def trainer(args, config, model, savepath):\n",
        "    # Initializations\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda:0\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    # Parameters\n",
        "    loss_function = config['loss_function']\n",
        "    optimizer = config['optimizer']\n",
        "    dataset_train = config['ds_train']\n",
        "    dataset_val = config['ds_val']\n",
        "    save_interval = config['save_interval']\n",
        "\n",
        "    def worker_init_fn(worker_id):\n",
        "        random.seed(args.seed + worker_id)\n",
        "\n",
        "    # Data Loaders\n",
        "    train_loader = DataLoader(dataset_train, batch_size=args.batch_size, shuffle=True, num_workers=16, pin_memory=True,\n",
        "                              worker_init_fn=worker_init_fn)\n",
        "    val_loader = DataLoader(dataset_val, batch_size=1, shuffle=True, num_workers=2, pin_memory=True,\n",
        "                            worker_init_fn=worker_init_fn)\n",
        "\n",
        "    max_iterations = args.max_epochs * len(train_loader)\n",
        "\n",
        "    # logging\n",
        "    logging.basicConfig(filename=args.save_path + \"/log.txt\", level=logging.INFO,\n",
        "                        format='[%(asctime)s.%(msecs)03d] %(message)s', datefmt='%H:%M:%S')\n",
        "    logging.info(args)\n",
        "    logging.info(\"{} iterations per epoch. {} max iterations \".format(len(train_loader), max_iterations))\n",
        "    writer = SummaryWriter(savepath + '/log')\n",
        "\n",
        "    best_metric = -1\n",
        "    best_metric_epoch = -1\n",
        "    metric_values = []\n",
        "    iter_num = 0\n",
        "\n",
        "    ############################\n",
        "    #         Training         #\n",
        "    ############################\n",
        "\n",
        "    for epoch in range(args.max_epochs):\n",
        "        epoch_loss = 0\n",
        "        model.train()\n",
        "        for i_batch, sampled_batch in enumerate(train_loader):\n",
        "            # get inputs and targets\n",
        "            inputs, targets = sampled_batch['image'], sampled_batch['label']\n",
        "            # here the input and target have the shape [batch, H, L, D]\n",
        "            # so we need to add the channel dimension\n",
        "            inputs, targets = inputs.unsqueeze(1), targets.unsqueeze(1)\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_function(outputs, targets)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # update learning rate\n",
        "            epoch_loss += loss\n",
        "            lr_ = args.base_lr * (1.0 - iter_num / max_iterations) ** 0.9\n",
        "            for param_group in optimizer.param_groups:\n",
        "                param_group['lr'] = lr_\n",
        "            lrlog = lr_\n",
        "            writer.add_scalar('info/lr', lr_, iter_num)\n",
        "            iter_num = iter_num + 1\n",
        "\n",
        "            # write to log\n",
        "            writer.add_scalar('info/total_loss', loss, iter_num)\n",
        "            # logging.info('iteration %d : loss : %f' % (iter_num, loss.item()))\n",
        "\n",
        "        epoch_loss = epoch_loss / len(train_loader)\n",
        "\n",
        "        logging.info('epoch %d : mean loss : %f' % (epoch, epoch_loss))\n",
        "\n",
        "        ############################\n",
        "        #        Validation        #\n",
        "        ############################\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            dice_tmp = []\n",
        "            for i_batch, sampled_batch in enumerate(val_loader):\n",
        "                # get inputs and targets\n",
        "                inputs, targets = sampled_batch['image'], sampled_batch['label']\n",
        "                # targets needs to be transformed to one-hot encoding\n",
        "                targets = targets.unsqueeze(1)\n",
        "                targets = one_hot_encoder(targets, args.num_classes)\n",
        "                inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "                val_outputs = model(inputs)\n",
        "                m = nn.Softmax(dim=1)\n",
        "                val_outputs = m(val_outputs)\n",
        "\n",
        "                # compute metric for current iteration\n",
        "                dice_tmp.append(dice_score(val_outputs.cpu().data.numpy(), targets.cpu().data.numpy()))\n",
        "\n",
        "            # aggregate the final mean dice result\n",
        "            metric = fmean(dice_tmp)\n",
        "\n",
        "            # write to log\n",
        "            writer.add_scalar('info/validation_metric', metric, epoch)\n",
        "            logging.info('iteration %d : dice score : %f' % (epoch, metric))\n",
        "\n",
        "            metric_values.append(metric)\n",
        "            if metric > best_metric:\n",
        "                best_metric = metric\n",
        "                best_metric_epoch = epoch + 1\n",
        "                torch.save(model.state_dict(), os.path.join(args.save_path, \"best_metric_model.pth\"))\n",
        "                print(\"saved new best metric model\")\n",
        "            print(\n",
        "                f\"current epoch: {epoch + 1} current mean dice: {metric:.4f}. Current learning rate {lrlog}\"\n",
        "                f\"\\nbest mean dice: {best_metric:.4f} \"\n",
        "                f\"at epoch: {best_metric_epoch}\"\n",
        "            )\n",
        "\n",
        "        ############################\n",
        "        #          Saving          #\n",
        "        ############################\n",
        "\n",
        "        # add an example to tensorboard logging\n",
        "        labs = to_one_arr_encoding(targets)\n",
        "        outputs = torch.argmax(torch.softmax(val_outputs, dim=1), dim=1, keepdim=True)\n",
        "\n",
        "        if len(inputs.shape) == 5:\n",
        "            image = inputs[:, :, :, :, round(args.img_size / 2)]\n",
        "            labs = labs[:, :, :, :, round(args.img_size / 2)]\n",
        "            outputs = outputs[:, :, :, round(args.img_size / 2)]\n",
        "        else:\n",
        "            image = inputs\n",
        "\n",
        "        image = image[0]\n",
        "        labs = torch.squeeze(labs * 50, 1)\n",
        "        outputs = outputs[0] * 50\n",
        "        image = (image - image.min()) / (image.max() - image.min())\n",
        "        writer.add_image('train/Image', image, iter_num)\n",
        "        writer.add_image('train/Prediction', outputs, iter_num)\n",
        "        writer.add_image('train/GroundTruth', labs, iter_num)\n",
        "\n",
        "        if (epoch + 1) % save_interval == 0:\n",
        "            save_mode_path = os.path.join(args.save_path, 'epoch_' + str(epoch) + '.pth')\n",
        "            torch.save(model.state_dict(), save_mode_path)\n",
        "            logging.info(\"save model to {}\".format(save_mode_path))\n",
        "\n",
        "        if epoch >= args.max_epochs - 1:\n",
        "            save_mode_path = os.path.join(args.save_path, 'epoch_' + str(epoch) + '.pth')\n",
        "            torch.save(model.state_dict(), save_mode_path)\n",
        "            logging.info(\"save model to {}\".format(save_mode_path))\n",
        "            break\n",
        "\n",
        "    writer.close()\n",
        "    return \"Training Finished!\""
      ],
      "metadata": {
        "id": "hN7Uh74THYNp"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "SfIBWohcpqej"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}