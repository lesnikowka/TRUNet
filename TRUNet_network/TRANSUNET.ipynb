{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "!pip install tensorboardX"
      ],
      "metadata": {
        "id": "p60S4qp5GG3B",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "11f98988-04b0-4a63-c396-ab6130e35184"
      },
      "execution_count": 5,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Collecting tensorboardX\n",
            "  Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl.metadata (5.8 kB)\n",
            "Requirement already satisfied: numpy in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (1.26.4)\n",
            "Requirement already satisfied: packaging in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (24.2)\n",
            "Requirement already satisfied: protobuf>=3.20 in /usr/local/lib/python3.10/dist-packages (from tensorboardX) (4.25.5)\n",
            "Downloading tensorboardX-2.6.2.2-py2.py3-none-any.whl (101 kB)\n",
            "\u001b[?25l   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/101.7 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K   \u001b[91m━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━\u001b[0m \u001b[32m71.7/101.7 kB\u001b[0m \u001b[31m2.1 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K   \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m101.7/101.7 kB\u001b[0m \u001b[31m1.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hInstalling collected packages: tensorboardX\n",
            "Successfully installed tensorboardX-2.6.2.2\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import logging\n",
        "import os\n",
        "import random\n",
        "import numpy as np\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "from tensorboardX import SummaryWriter\n",
        "from torch.utils.data import DataLoader\n",
        "from statistics import fmean\n",
        "\n",
        "\n",
        "def dice_score(pred, gt):  # data in shape [batch, classes, h, w, d]\n",
        "    dice = []\n",
        "    for batchloop in range(gt.shape[0]):\n",
        "        dice_tmp = []\n",
        "        for roi in range(gt.shape[1]):\n",
        "            if roi > 0:  # skip background\n",
        "                pred_tmp = pred[int(batchloop), int(roi)]\n",
        "                gt_tmp = gt[int(batchloop), int(roi)]\n",
        "                a = np.sum(pred_tmp[gt_tmp == 1])\n",
        "                b = np.sum(pred_tmp)\n",
        "                c = np.sum(gt_tmp)\n",
        "                if a == 0:\n",
        "                    metric = 0\n",
        "                else:\n",
        "                    metric_ = a * 2.0 / (b + c)\n",
        "                    metric = metric_.item()\n",
        "                dice_tmp.append(metric)\n",
        "        dice.append(fmean(dice_tmp))\n",
        "    return fmean(dice)\n",
        "\n",
        "\n",
        "def one_hot_encoder(input_tensor, n_classes):\n",
        "    tensor_list = []\n",
        "    for i in range(n_classes):\n",
        "        temp_prob = input_tensor == i  # * torch.ones_like(input_tensor)\n",
        "        tensor_list.append(temp_prob)\n",
        "    output_tensor = torch.cat(tensor_list, dim=1)\n",
        "    return output_tensor.float()\n",
        "\n",
        "\n",
        "def to_one_arr_encoding(input_tensor):  # input shape: [batch, channels, h, w, d]\n",
        "    new_arr = torch.zeros(input_tensor.shape)\n",
        "    for batchloop in range(input_tensor.shape[0]):\n",
        "        for d in range(input_tensor.shape[1]):\n",
        "            new_arr[batchloop, d] = torch.where(input_tensor[batchloop, d] == 1, d + 1, 0)\n",
        "    return new_arr.sum(1).unsqueeze(1)\n",
        "\n",
        "\n",
        "def trainer(args, config, model, savepath):\n",
        "    # Initializations\n",
        "    if torch.cuda.is_available():\n",
        "        device = torch.device(\"cuda:0\")\n",
        "    else:\n",
        "        device = torch.device(\"cpu\")\n",
        "    model.to(device)\n",
        "\n",
        "    # Parameters\n",
        "    loss_function = config['loss_function']\n",
        "    optimizer = config['optimizer']\n",
        "    dataset_train = config['ds_train']\n",
        "    dataset_val = config['ds_val']\n",
        "    save_interval = config['save_interval']\n",
        "\n",
        "    def worker_init_fn(worker_id):\n",
        "        random.seed(args.seed + worker_id)\n",
        "\n",
        "    # Data Loaders\n",
        "    train_loader = DataLoader(dataset_train, batch_size=args.batch_size, shuffle=True, num_workers=16, pin_memory=True,\n",
        "                              worker_init_fn=worker_init_fn)\n",
        "    val_loader = DataLoader(dataset_val, batch_size=1, shuffle=True, num_workers=2, pin_memory=True,\n",
        "                            worker_init_fn=worker_init_fn)\n",
        "\n",
        "    max_iterations = args.max_epochs * len(train_loader)\n",
        "\n",
        "    # logging\n",
        "    logging.basicConfig(filename=args.save_path + \"/log.txt\", level=logging.INFO,\n",
        "                        format='[%(asctime)s.%(msecs)03d] %(message)s', datefmt='%H:%M:%S')\n",
        "    logging.info(args)\n",
        "    logging.info(\"{} iterations per epoch. {} max iterations \".format(len(train_loader), max_iterations))\n",
        "    writer = SummaryWriter(savepath + '/log')\n",
        "\n",
        "    best_metric = -1\n",
        "    best_metric_epoch = -1\n",
        "    metric_values = []\n",
        "    iter_num = 0\n",
        "\n",
        "    ############################\n",
        "    #         Training         #\n",
        "    ############################\n",
        "\n",
        "    for epoch in range(args.max_epochs):\n",
        "        epoch_loss = 0\n",
        "        model.train()\n",
        "        for i_batch, sampled_batch in enumerate(train_loader):\n",
        "            # get inputs and targets\n",
        "            inputs, targets = sampled_batch['image'], sampled_batch['label']\n",
        "            # here the input and target have the shape [batch, H, L, D]\n",
        "            # so we need to add the channel dimension\n",
        "            inputs, targets = inputs.unsqueeze(1), targets.unsqueeze(1)\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = loss_function(outputs, targets)\n",
        "\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "\n",
        "            # update learning rate\n",
        "            epoch_loss += loss\n",
        "            lr_ = args.base_lr * (1.0 - iter_num / max_iterations) ** 0.9\n",
        "            for param_group in optimizer.param_groups:\n",
        "                param_group['lr'] = lr_\n",
        "            lrlog = lr_\n",
        "            writer.add_scalar('info/lr', lr_, iter_num)\n",
        "            iter_num = iter_num + 1\n",
        "\n",
        "            # write to log\n",
        "            writer.add_scalar('info/total_loss', loss, iter_num)\n",
        "            # logging.info('iteration %d : loss : %f' % (iter_num, loss.item()))\n",
        "\n",
        "        epoch_loss = epoch_loss / len(train_loader)\n",
        "\n",
        "        logging.info('epoch %d : mean loss : %f' % (epoch, epoch_loss))\n",
        "\n",
        "        ############################\n",
        "        #        Validation        #\n",
        "        ############################\n",
        "\n",
        "        model.eval()\n",
        "        with torch.no_grad():\n",
        "            dice_tmp = []\n",
        "            for i_batch, sampled_batch in enumerate(val_loader):\n",
        "                # get inputs and targets\n",
        "                inputs, targets = sampled_batch['image'], sampled_batch['label']\n",
        "                # targets needs to be transformed to one-hot encoding\n",
        "                targets = targets.unsqueeze(1)\n",
        "                targets = one_hot_encoder(targets, args.num_classes)\n",
        "                inputs, targets = inputs.to(device), targets.to(device)\n",
        "\n",
        "                val_outputs = model(inputs)\n",
        "                m = nn.Softmax(dim=1)\n",
        "                val_outputs = m(val_outputs)\n",
        "\n",
        "                # compute metric for current iteration\n",
        "                dice_tmp.append(dice_score(val_outputs.cpu().data.numpy(), targets.cpu().data.numpy()))\n",
        "\n",
        "            # aggregate the final mean dice result\n",
        "            metric = fmean(dice_tmp)\n",
        "\n",
        "            # write to log\n",
        "            writer.add_scalar('info/validation_metric', metric, epoch)\n",
        "            logging.info('iteration %d : dice score : %f' % (epoch, metric))\n",
        "\n",
        "            metric_values.append(metric)\n",
        "            if metric > best_metric:\n",
        "                best_metric = metric\n",
        "                best_metric_epoch = epoch + 1\n",
        "                torch.save(model.state_dict(), os.path.join(args.save_path, \"best_metric_model.pth\"))\n",
        "                print(\"saved new best metric model\")\n",
        "            print(\n",
        "                f\"current epoch: {epoch + 1} current mean dice: {metric:.4f}. Current learning rate {lrlog}\"\n",
        "                f\"\\nbest mean dice: {best_metric:.4f} \"\n",
        "                f\"at epoch: {best_metric_epoch}\"\n",
        "            )\n",
        "\n",
        "        ############################\n",
        "        #          Saving          #\n",
        "        ############################\n",
        "\n",
        "        # add an example to tensorboard logging\n",
        "        labs = to_one_arr_encoding(targets)\n",
        "        outputs = torch.argmax(torch.softmax(val_outputs, dim=1), dim=1, keepdim=True)\n",
        "\n",
        "        if len(inputs.shape) == 5:\n",
        "            image = inputs[:, :, :, :, round(args.img_size / 2)]\n",
        "            labs = labs[:, :, :, :, round(args.img_size / 2)]\n",
        "            outputs = outputs[:, :, :, round(args.img_size / 2)]\n",
        "        else:\n",
        "            image = inputs\n",
        "\n",
        "        image = image[0]\n",
        "        labs = torch.squeeze(labs * 50, 1)\n",
        "        outputs = outputs[0] * 50\n",
        "        image = (image - image.min()) / (image.max() - image.min())\n",
        "        writer.add_image('train/Image', image, iter_num)\n",
        "        writer.add_image('train/Prediction', outputs, iter_num)\n",
        "        writer.add_image('train/GroundTruth', labs, iter_num)\n",
        "\n",
        "        if (epoch + 1) % save_interval == 0:\n",
        "            save_mode_path = os.path.join(args.save_path, 'epoch_' + str(epoch) + '.pth')\n",
        "            torch.save(model.state_dict(), save_mode_path)\n",
        "            logging.info(\"save model to {}\".format(save_mode_path))\n",
        "\n",
        "        if epoch >= args.max_epochs - 1:\n",
        "            save_mode_path = os.path.join(args.save_path, 'epoch_' + str(epoch) + '.pth')\n",
        "            torch.save(model.state_dict(), save_mode_path)\n",
        "            logging.info(\"save model to {}\".format(save_mode_path))\n",
        "            break\n",
        "\n",
        "    writer.close()\n",
        "    return \"Training Finished!\""
      ],
      "metadata": {
        "id": "bU1pVxdAHGs_"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "hN7Uh74THYNp"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}